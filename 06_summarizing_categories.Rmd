# Summarizing Categorical Variables

Summarizing categorical variables numerically is mostly about building tables, and calculating percentages or proportions. We'll save our discussion of modeling categorical data for later. Recall that in the `nh_adults` data set we built in Section (\@ref(createnh_adults)), we had the following categorical variables. The number of levels indicates the number of possible categories for each categorical variable.

Variable     | Description                  | Levels | Type
----------:  | ---------------------------- | - | ---------
Sex          | sex of subject               | 2 | binary
Race         | subject's race               | 6 | nominal
Education    | subject's educational level  | 5 | ordinal
PhysActive   | Participates in sports?      | 2 | binary
Smoke100     | Smoked 100+ cigarettes?      | 2 | binary
SleepTrouble | Trouble sleeping?            | 2 | binary
HealthGen    | Self-report health           | 5 | ordinal

## The `summary` function for Categorical data

When R recognizes a variable as categorical, it stores it as a *factor*. Such variables get special treatment from the `summary` function, in particular a table of available values (so long as there aren't too many.)

```{r nh-adultscategorical-summ1}
nh_adults %>%
  select(Sex, Race, Education, PhysActive, Smoke100, SleepTrouble, HealthGen) %>%
  summary()
```

## Tables to describe One Categorical Variable

Suppose we build a table to describe the `HealthGen` distribution.

```{r nh_adults_HealthGen_counts}
nh_adults %>%
    select(HealthGen) %>%
    table(., useNA = "ifany")
```

The main tools we have for augmenting tables are:
    
- adding in marginal totals, and 
- working with proportions/percentages.

What if we want to add a total count?

```{r nh_adults_HealthGen_countsandmargins}
nh_adults %>%
    select(HealthGen) %>%
    table(., useNA = "ifany") %>%
    addmargins()
```

What if we want to leave out the missing responses?

```{r nh_adults_HealthGen_countsandmarginsnoNA}
nh_adults %>%
    select(HealthGen) %>%
    table(., useNA = "no") %>%
    addmargins()
```

Let's put the missing values back in, but now calculate proportions instead. Since the total will just be 1.0, we'll leave that out.

```{r nh_adults_HealthGen_proportions}
nh_adults %>%
    select(HealthGen) %>%
    table(., useNA = "ifany") %>%
    prop.table()
```

Now, we'll calculate percentages by multiplying the proportions by 100.

```{r nh_adults_HealthGen_percentages}
nh_adults %>%
    select(HealthGen) %>%
    table(., useNA = "ifany") %>%
    prop.table() %>%
    "*"(100) 
```

## The Mode of a Categorical Variable

A common measure applied to a categorical variable is to identify the mode, the most frequently observed value. To find the mode for variables with lots of categories (so that the `summary` may not be sufficient), we usually tabulate the data, and then sort by the counts of the numbers of observations, as we did with discrete quantitative variables.

```{r mode_nh_adults_HealthGen}
nh_adults %>%
    group_by(HealthGen) %>%
    summarise(count = n()) %>%
    arrange(desc(count)) 
```

## `describe` in the `Hmisc` package

```{r Hmisc-describe-nh_adults_categorical}
Hmisc::describe(nh_adults %>% 
                    select(Sex, Race, Education, PhysActive, 
                           Smoke100, SleepTrouble, HealthGen))
```

## Cross-Tabulations 

It is very common for us to want to describe the association of one categorical variable with another. For instance, is there a relationship between Education and SleepTrouble in these data?

```{r crosstab1-nh_adults_education_sleep}
nh_adults %>%
    select(Education, SleepTrouble) %>%
    table() %>%
    addmargins()
```

To get row percentages, we can use:

```{r crosstab1-nh_adults_education_sleep2}
nh_adults %>%
    select(Education, SleepTrouble) %>%
    table() %>%
    prop.table(., 1) %>%
    "*"(100) 
```

For column percentages, we use 2 instead of 1 in the `prop.table` function. Here, we'll also round off to two decimal places:

```{r crosstab1-nh_adults_education_sleep3}
nh_adults %>%
    select(Education, SleepTrouble) %>%
    table() %>%
    prop.table(., 2) %>%
    "*"(100) %>%
    round(.,2) 
```

Here's another approach, to look at the cross-classification of Race and HealthGen:

```{r crosstab2-nh_adults_race_healthgen}
xtabs(~ Race + HealthGen, data = nh_adults)
```

### Cross-Classifying Three Categorical Variables

Suppose we are interested in `Smoke100` and its relationship to `PhysActive` and `SleepTrouble`.

```{r nh_adults_crosstab-3ways1}
xtabs(~ Smoke100 + PhysActive + SleepTrouble, data = nh_adults)
```

We can also build a **flat** version of this table, as follows:

```{r nh_adults_crosstab-3ways2}
ftable(Smoke100 ~ PhysActive + SleepTrouble, data = nh_adults)
```


And we can do this with `dplyr` functions, as well, for example...

```{r nh_adults_crosstab-3ways3}
nh_adults %>%
    select(Smoke100, PhysActive, SleepTrouble) %>%
    table() 
```

## Constructing Tables Well

The prolific Howard Wainer is responsible for many interesting books on visualization and related issues, including @HW_GraphicDiscovery and @HW_MedicalIlluminations. These rules come from Chapter 10 of @HW_VisualRevelations.

1. Order the rows and columns in a way that makes sense.
2. Round, a lot!
3. ALL is different and important

### Alabama First!

Which of these Tables is more useful to you?
    
2013 Percent of Students in grades 9-12 who are obese

State | % Obese | 95% CI | Sample Size
----- | ------- | ------ | -----------
Alabama | 17.1 | (14.6 - 19.9) | 1,499
Alaska |	12.4	| (10.5-14.6)	| 1,167
Arizona |	10.7 |	(8.3-13.6)	| 1,520
Arkansas |	17.8	| (15.7-20.1)	| 1,470
Connecticut |	12.3 |	(10.2-14.7)	| 2,270
Delaware |	14.2 |	(12.9-15.6) |	2,475
Florida |	11.6	| (10.5-12.8)	| 5,491
... | | | 
Wisconsin |	11.6 | 	(9.7-13.9)	| 2,771
Wyoming	| 10.7 |	(9.4-12.2)	| 2,910

or ...

State | % Obese | 95% CI | Sample Size
----- | ------- | ------ | -----------
Kentucky | 18.0 | (15.7 - 20.6) | 1,537
Arkansas | 17.8 | (15.7 - 20.1) | 1,470
Alabama | 17.1 | (14.6 - 19.9) | 1,499
Tennessee | 16.9 | (15.1 - 18.8) | 1,831
Texas | 15.7 | (13.9 - 17.6) | 3,039
... | | |
Massachusetts | 10.2 | (8.5 - 12.1) | 2,547
Idaho | 9.6 | (8.2 - 11.1) | 1,841
Montana | 9.4 | (8.4 - 10.5) | 4,679
New Jersey | 8.7 | (6.8 - 11.2) | 1,644
Utah | 6.4 | (4.8 - 8.5) | 2,136

It is a rare event when Alabama first is the best choice.

### Order rows and columns sensibly

- Alabama First!
    + Size places - put the largest first. We often look most carefully at the top.
- Order time from the past to the future to help the viewer.
- If there is a clear predictor-outcome relationship, put the predictors in the rows and the outcomes in the columns.

### Round - a lot!

- Humans cannot understand more than two digits very easily.
- We almost never care about accuracy of more than two digits.
- We can almost never justify more than two digits of accuracy statistically.
- It's also helpful to remember that we are almost invariably publishing progress to date, rather than a truly final answer.

Suppose, for instance, we report a correlation coefficient of 0.25. How many observations do you think you would need to justify such a choice?

- To report 0.25 meaningfully, we want to be sure that the second digit isn't 4 or 6.
- That requires a standard error less than 0.005
- The *standard error* of any statistic is proportional to 1 over the square root of the sample size, *n*.

So $\frac{1}{\sqrt{n}}$ ~ 0.005, but that means $\sqrt{n} = \frac{1}{0.005} = 200$. If $\sqrt{n} = 200$, then *n* = (200)^2^ = 40,000. 

Do we usually have 40,000 observations?

### ALL is different and important

Summaries of rows and columns provide a measure of what is typical or usual. Sometimes a sum is helpful, at other times, consider presenting a median or other summary. The ALL category, as @HW_VisualRevelations suggests, should be both visually different from the individual entries and set spatially apart.

On the whole, it's *far* easier to fall into a good graph in R (at least if you have some ggplot2 skills) than to produce a good table.
